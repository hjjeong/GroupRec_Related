{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.agree_ori import AGREE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from time import time\n",
    "from config_CA import Config\n",
    "from utils.util import Helper\n",
    "from dataset_Meetup import GDataset\n",
    "import datetime\n",
    "from batch_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_loader, epoch_id, config):\n",
    "    # user trainning\n",
    "    learning_rates = config.lr\n",
    "    lr = learning_rates[0]\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    losses = []\n",
    "\n",
    "    *_, last = train_loader\n",
    "\n",
    "    for batch_id, (g, pi_ni) in enumerate(train_loader):\n",
    "        # Data Load\n",
    "        group_input = g\n",
    "        pos_item_input = pi_ni[:, 0]\n",
    "        neg_item_input = pi_ni[:, 1]\n",
    "\n",
    "        pos_prediction = model(group_input, pos_item_input)\n",
    "        neg_prediction = model(group_input, neg_item_input)\n",
    "\n",
    "        # Zero_grad\n",
    "        model.zero_grad()\n",
    "        # Loss\n",
    "        #loss = torch.mean((pos_prediction - neg_prediction -1) **2)\n",
    "        eps = 1e-7\n",
    "        loss = torch.mean(-torch.log(pos_prediction+eps)-torch.log(1.0-neg_prediction+eps))\n",
    "        # record loss history\n",
    "        #print(\"batch_id: \" + str(batch_id) + \" loss: \" + str(loss.item()))\n",
    "        if not torch.isinf(loss.data) and not torch.isnan(loss.data):\n",
    "            losses.append(float(loss.item()))\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Iteration %d, loss is [%.4f ]' % (epoch_id, np.mean(np.array(losses))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, groups_to_test, Ks, trainRatings, num_items):\n",
    "    model.eval()\n",
    "    ret = test(model, groups_to_test, Ks, trainRatings, num_items)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meetup.ca 80 256\n"
     ]
    }
   ],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = Helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "print(config.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_groups: 607 num_users: 56878 num_items: 1490\n",
      "AGREE: embedding size 32, run Iteration: 80, #neg: 4, NDCG@, HR@10\n",
      "Iteration 0, loss is [1.1481 ]\n",
      "one epoch done: [156.4 s]\n",
      "Group Iteration 0 [533.5 s]: HR = 0.2126, NDCG = 0.0893, Rec = 0.1063\n",
      "Iteration 1, loss is [0.9333 ]\n",
      "one epoch done: [150.3 s]\n",
      "Group Iteration 1 [524.9 s]: HR = 0.2184, NDCG = 0.1410, Rec = 0.1240\n",
      "Iteration 2, loss is [0.7759 ]\n",
      "one epoch done: [148.8 s]\n",
      "Group Iteration 2 [499.6 s]: HR = 0.2126, NDCG = 0.1029, Rec = 0.1169\n",
      "Iteration 3, loss is [0.6328 ]\n",
      "one epoch done: [145.7 s]\n",
      "Group Iteration 3 [523.2 s]: HR = 0.2759, NDCG = 0.1575, Rec = 0.1609\n",
      "Iteration 4, loss is [0.5183 ]\n",
      "one epoch done: [156.2 s]\n",
      "Group Iteration 4 [507.3 s]: HR = 0.2816, NDCG = 0.1415, Rec = 0.1758\n",
      "Iteration 5, loss is [0.4211 ]\n",
      "one epoch done: [155.7 s]\n",
      "Group Iteration 5 [513.0 s]: HR = 0.3218, NDCG = 0.1596, Rec = 0.2155\n",
      "Iteration 6, loss is [0.3492 ]\n",
      "one epoch done: [151.3 s]\n",
      "Group Iteration 6 [517.4 s]: HR = 0.3506, NDCG = 0.1671, Rec = 0.2251\n",
      "Iteration 7, loss is [0.2910 ]\n",
      "one epoch done: [156.9 s]\n",
      "Group Iteration 7 [512.8 s]: HR = 0.3448, NDCG = 0.1717, Rec = 0.2107\n",
      "Iteration 8, loss is [0.2467 ]\n",
      "one epoch done: [143.2 s]\n",
      "Group Iteration 8 [518.2 s]: HR = 0.3103, NDCG = 0.1541, Rec = 0.1944\n",
      "Iteration 9, loss is [0.2123 ]\n",
      "one epoch done: [151.0 s]\n",
      "Group Iteration 9 [509.2 s]: HR = 0.3621, NDCG = 0.1898, Rec = 0.2203\n",
      "Iteration 10, loss is [0.1766 ]\n",
      "one epoch done: [151.1 s]\n",
      "Group Iteration 10 [522.4 s]: HR = 0.3793, NDCG = 0.1979, Rec = 0.2371\n",
      "Iteration 11, loss is [0.1619 ]\n",
      "one epoch done: [155.8 s]\n",
      "Group Iteration 11 [523.8 s]: HR = 0.4138, NDCG = 0.1921, Rec = 0.2605\n",
      "Iteration 12, loss is [0.1428 ]\n",
      "one epoch done: [154.8 s]\n",
      "Group Iteration 12 [527.3 s]: HR = 0.4138, NDCG = 0.1944, Rec = 0.2519\n",
      "Iteration 13, loss is [0.1310 ]\n",
      "one epoch done: [150.2 s]\n",
      "Group Iteration 13 [528.5 s]: HR = 0.3793, NDCG = 0.2074, Rec = 0.2356\n",
      "Iteration 14, loss is [0.1226 ]\n",
      "one epoch done: [147.6 s]\n",
      "Group Iteration 14 [536.0 s]: HR = 0.4023, NDCG = 0.2204, Rec = 0.2567\n",
      "Iteration 15, loss is [0.1122 ]\n",
      "one epoch done: [156.8 s]\n",
      "Group Iteration 15 [518.9 s]: HR = 0.4023, NDCG = 0.1910, Rec = 0.2447\n",
      "Iteration 16, loss is [0.1070 ]\n",
      "one epoch done: [155.6 s]\n",
      "Group Iteration 16 [512.4 s]: HR = 0.4253, NDCG = 0.2080, Rec = 0.2711\n",
      "Iteration 17, loss is [0.0983 ]\n",
      "one epoch done: [142.6 s]\n",
      "Group Iteration 17 [506.7 s]: HR = 0.4368, NDCG = 0.2095, Rec = 0.2816\n",
      "Iteration 18, loss is [0.0933 ]\n",
      "one epoch done: [152.1 s]\n",
      "Group Iteration 18 [518.5 s]: HR = 0.4253, NDCG = 0.2188, Rec = 0.2878\n",
      "Iteration 19, loss is [0.1027 ]\n",
      "one epoch done: [152.5 s]\n",
      "Group Iteration 19 [520.6 s]: HR = 0.4540, NDCG = 0.2329, Rec = 0.2969\n",
      "Iteration 20, loss is [0.0949 ]\n",
      "one epoch done: [148.1 s]\n",
      "Group Iteration 20 [516.1 s]: HR = 0.4655, NDCG = 0.2553, Rec = 0.3012\n",
      "Iteration 21, loss is [0.0863 ]\n",
      "one epoch done: [151.9 s]\n",
      "Group Iteration 21 [529.3 s]: HR = 0.4598, NDCG = 0.2751, Rec = 0.3056\n",
      "Iteration 22, loss is [0.0914 ]\n",
      "one epoch done: [155.4 s]\n",
      "Group Iteration 22 [495.8 s]: HR = 0.4310, NDCG = 0.2447, Rec = 0.2840\n",
      "Iteration 23, loss is [0.0821 ]\n",
      "one epoch done: [151.6 s]\n",
      "Group Iteration 23 [500.6 s]: HR = 0.4540, NDCG = 0.2454, Rec = 0.3041\n",
      "Iteration 24, loss is [0.0858 ]\n",
      "one epoch done: [156.1 s]\n",
      "Group Iteration 24 [516.3 s]: HR = 0.4713, NDCG = 0.2395, Rec = 0.2998\n",
      "Iteration 25, loss is [0.0900 ]\n",
      "one epoch done: [150.9 s]\n",
      "Group Iteration 25 [529.4 s]: HR = 0.4655, NDCG = 0.2458, Rec = 0.3080\n",
      "Iteration 26, loss is [0.0838 ]\n",
      "one epoch done: [154.0 s]\n",
      "Group Iteration 26 [525.6 s]: HR = 0.4540, NDCG = 0.2417, Rec = 0.2840\n",
      "Iteration 27, loss is [0.0864 ]\n",
      "one epoch done: [151.9 s]\n",
      "Group Iteration 27 [521.3 s]: HR = 0.4483, NDCG = 0.2436, Rec = 0.2850\n",
      "Iteration 28, loss is [0.0832 ]\n",
      "one epoch done: [155.3 s]\n",
      "Group Iteration 28 [519.2 s]: HR = 0.4253, NDCG = 0.2196, Rec = 0.2625\n",
      "Iteration 29, loss is [0.0804 ]\n",
      "one epoch done: [156.4 s]\n",
      "Group Iteration 29 [534.1 s]: HR = 0.4195, NDCG = 0.2148, Rec = 0.2658\n"
     ]
    }
   ],
   "source": [
    "dataset = GDataset(config.user_dataset, config.group_dataset, config.user_in_group_path, 1)\n",
    "num_groups, num_users, num_items = dataset.num_groups, dataset.num_users, dataset.num_items\n",
    "print(\"num_groups: \"+str(num_groups)+\" num_users: \"+str(num_users)+\" num_items: \"+str(num_items))\n",
    "\n",
    "agree = AGREE(num_users, num_items, num_groups, config.embedding_size, dataset.gu_dict, config.drop_ratio).cuda()\n",
    "\n",
    "for num_negatives in config.num_negatives:\n",
    "    dataset.num_negatives = num_negatives\n",
    "    print(\"AGREE: embedding size %d, run Iteration: %d, #neg: %d, NDCG@, HR@%d\" %(config.embedding_size, config.epoch, num_negatives, config.topK[1]))\n",
    "    # train the model\n",
    "    now = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    for epoch in range(30+0*config.epoch):\n",
    "        agree.train()\n",
    "        t1 = time()\n",
    "        training(agree, dataset.get_group_dataloader(config.batch_size), epoch, config)\n",
    "        t2 = time()\n",
    "        print(\"one epoch done: [%.1f s]\" % (t2 - t1))\n",
    "        # Evaluation\n",
    "\n",
    "        ret = evaluation(agree, dataset.group_testRatings, config.topK, dataset.group_trainRatings, dataset.num_items)\n",
    "        hr1 = ret['hit_ratio'][0]\n",
    "        ndcg1 = ret['ndcg'][0]\n",
    "        rec1 = ret['recall'][0]\n",
    "        hr2 = ret['hit_ratio'][1]\n",
    "        ndcg2 = ret['ndcg'][1]\n",
    "        rec2 = ret['recall'][1]\n",
    "        hr3 = ret['hit_ratio'][2]\n",
    "        ndcg3 = ret['ndcg'][2]\n",
    "        rec3 = ret['recall'][2]\n",
    "        hr4 = ret['hit_ratio'][3]\n",
    "        ndcg4 = ret['ndcg'][3]\n",
    "        rec4 = ret['recall'][3]\n",
    "        hr5 = ret['hit_ratio'][4]\n",
    "        ndcg5 = ret['ndcg'][4]\n",
    "        rec5 = ret['recall'][4]\n",
    "        pre1 = ret['precision'][0]\n",
    "        pre2 = ret['precision'][1]\n",
    "        pre3 = ret['precision'][2]\n",
    "        pre4 = ret['precision'][3]\n",
    "        pre5 = ret['precision'][4]\n",
    "\n",
    "        print('Group Iteration %d [%.1f s]: HR = %.4f, NDCG = %.4f, Rec = %.4f' % (\n",
    "        epoch, time() - t2, hr2, ndcg2, rec2))\n",
    "        '''\n",
    "        f.write(str(hr1) + \",\" + str(hr2) + \",\" + str(hr3) + \",\" + str(hr4) + \",\" + str(hr5) + \",\" + \\\n",
    "                str(ndcg1) + \",\" + str(ndcg2) + \",\" + str(ndcg3) + \",\" + str(ndcg4) + \",\" + str(ndcg5) + \",\" + \\\n",
    "                str(rec1) + \",\" + str(rec2) + \",\" + str(rec3) + \",\" + str(rec4) + \",\" + str(rec5) + \",\" + \\\n",
    "                str(pre1) + \",\" + str(pre2) + \",\" + str(pre3) + \",\" + str(pre4) + \",\" + str(pre5) + \"\\n\")\n",
    "        '''\n",
    "    #f.close()\n",
    "    #f1.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_warm = dataset.load_rating_file_as_dict(config.group_dataset + \".test.rating_warm\")\n",
    "test_cold = dataset.load_rating_file_as_dict(config.group_dataset + \".test.rating_cold\")\n",
    "cold_groups = []\n",
    "for g in test_cold.keys():\n",
    "    cold_groups.append(g)\n",
    "cold_group_indicies = torch.LongTensor(cold_groups)\n",
    "g_shape = agree.groupembeds.groupEmbedding.weight[cold_group_indicies].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utest_one_group(x, model, Ks, group_trainRatings, group_testRatings, num_items, threshold, num_repeat):\n",
    "    #rating = x[0]\n",
    "    g = x #group 1개 들어옴\n",
    "\n",
    "    try:\n",
    "        training_items = group_trainRatings[g]\n",
    "    except Exception:\n",
    "        training_items = []\n",
    "\n",
    "    group_pos_test = group_testRatings[g]\n",
    "\n",
    "    all_items = set(range(num_items))\n",
    "\n",
    "    test_items = list(all_items-set(training_items))\n",
    "    one_group_batch = np.full(len(test_items),g)\n",
    "    group_var = torch.LongTensor(one_group_batch)\n",
    "    item_var = torch.LongTensor(test_items)\n",
    "    \n",
    "    rating_mean = 0\n",
    "    rating_var = 0\n",
    "    for _ in range(num_repeat):\n",
    "        with torch.no_grad():\n",
    "            model.groupembeds.groupEmbedding.weight[cold_group_indicies] = (torch.randn(g_shape)*5).cuda()\n",
    "        rating = model(group_var, item_var).cpu()\n",
    "        rating = rating.data.numpy()\n",
    "        rating_mean += rating\n",
    "        \n",
    "    rating_mean = rating_mean/num_repeat\n",
    "    eps = 1e-7\n",
    "    rating_var = -rating_mean*np.log(rating_mean+eps)-(1-rating_mean)*np.log(1-rating_mean+eps)\n",
    "\n",
    "    test_idx1 = np.where(rating_var<threshold)[0] #Total\n",
    "    \n",
    "    test_idx2 = np.where(rating_mean>=0.5)[0] \n",
    "    test_idx = list(set(test_idx1) & set(test_idx2)) #Correct\n",
    "    TP= set(np.array(test_items)[test_idx]) & set(group_pos_test)\n",
    "\n",
    "    return len(TP),  len(test_idx)\n",
    "\n",
    "def utest(model, groups_to_test, Ks, group_trainRatings, num_items, threshold=0.0, num_repeat=20):\n",
    "\n",
    "\n",
    "    #pool = multiprocessing.Pool(cores)\n",
    "\n",
    "    #g_batch_size = BATCH_SIZE\n",
    "    test_groups = groups_to_test\n",
    "    n_test_groups = len(test_groups)\n",
    "    #n_group_batchs = n_test_groups // g_batch_size + 1\n",
    "    #print(n_group_batchs)\n",
    "    counts = 0\n",
    "    corrects =0 \n",
    "    for g_id in test_groups:\n",
    "        inter, total = utest_one_group(g_id, model, Ks, group_trainRatings, test_groups, num_items, threshold, num_repeat)\n",
    "        corrects += inter\n",
    "        counts += total\n",
    "    if counts == 0:\n",
    "        counts = 1\n",
    "        corrects = 1\n",
    "    return corrects/counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uevaluation(model, groups_to_test, Ks, trainRatings, num_items, threshold=0.0, num_repeat=10):\n",
    "    model.eval()\n",
    "    t2 = time()\n",
    "    ret = utest(model, groups_to_test, Ks, trainRatings, num_items, threshold=threshold, num_repeat=num_repeat) #See batch_test\n",
    "\n",
    "    print('\\t Evaluation done [%.1f s]: Acc = %.4f' % (time() - t2, ret))\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Evaluation done [5175.5 s]: Acc = 0.0664\n",
      "\t Evaluation done [5177.1 s]: Acc = 0.0582\n",
      "\t Evaluation done [5188.1 s]: Acc = 0.0546\n",
      "\t Evaluation done [5127.0 s]: Acc = 0.0514\n",
      "\t Evaluation done [5210.9 s]: Acc = 0.0496\n",
      "\t Evaluation done [5123.7 s]: Acc = 0.0464\n",
      "\t Evaluation done [5198.7 s]: Acc = 0.0388\n",
      "\t Evaluation done [5146.0 s]: Acc = 0.0418\n",
      "\t Evaluation done [5186.6 s]: Acc = 0.0393\n",
      "\t Evaluation done [5154.7 s]: Acc = 0.0405\n"
     ]
    }
   ],
   "source": [
    "tttt = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "for ttt in tttt:\n",
    "    ret = uevaluation(agree, dataset.group_testRatings, config.topK[:2], dataset.group_trainRatings, dataset.num_items, threshold=ttt, num_repeat=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def evaluation(model, groups_to_test, Ks, trainRatings, num_items):\n",
    "    model.eval()\n",
    "    t2 = time()\n",
    "    ret = test(model, groups_to_test, Ks, trainRatings, num_items) #See batch_test\n",
    "\n",
    "    print('\\t Evaluation done [%.1f s]' % (time() - t2))\n",
    "    for i, k in enumerate(Ks):\n",
    "        print('\\t\\t @%d: HR = %.4f, NDCG = %.4f, Rec = %.4f' % (k, ret['hit_ratio'][i], ret['ndcg'][i], ret['recall'][i]))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ret = evaluation(agree, test_warm, config.topK[:2], dataset.group_trainRatings, dataset.num_items)  \n",
    "for _ in range(6):\n",
    "    with torch.no_grad():\n",
    "        agree.groupembeds.groupEmbedding.weight[cold_group_indicies] = 2*torch.randn(g_shape).cuda()\n",
    "    print('total')\n",
    "    ret = evaluation(agree, dataset.group_testRatings, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "\n",
    "    print('cold')\n",
    "    ret = evaluation(agree, test_cold, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "    #print('warm')\n",
    "    #ret = evaluation(agree, test_warm, config.topK[:2], dataset.group_trainRatings, dataset.num_items)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
