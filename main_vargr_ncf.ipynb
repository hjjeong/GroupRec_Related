{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "#Python Libs\n",
    "import numpy as np\n",
    "from time import time\n",
    "import datetime\n",
    "#Implementations\n",
    "from model.agree_re import VARGR_NCF, NCF\n",
    "from config_CA import Config\n",
    "from dataset_Meetup import GDataset\n",
    "from batch_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WU_point = 20\n",
    "def training(model, train_loader, epoch_id, config):\n",
    "    # user trainning\n",
    "    t1 = time()\n",
    "    model.train()\n",
    "    learning_rates = config.lr\n",
    "    lr = learning_rates[0] #if epoch_id<WU_point else 0.01\n",
    "    beta = 0.0 if epoch_id<WU_point else 1.0\n",
    "    # optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    *_, last = train_loader\n",
    "\n",
    "    for batch_id, (g, pi_ni) in enumerate(train_loader):\n",
    "        # Data Load\n",
    "        group_input = g\n",
    "        pos_item_input = pi_ni[:, 0]\n",
    "        neg_item_input = pi_ni[:, 1]\n",
    "\n",
    "        pos_prediction, dkl = model(group_input, pos_item_input, is_training=True)\n",
    "        neg_prediction, _ = model(group_input, neg_item_input, is_training=True)\n",
    "\n",
    "        # Zero_grad\n",
    "        model.zero_grad()\n",
    "        # Loss\n",
    "        eps=1e-7\n",
    "        loss = torch.mean(-torch.log(pos_prediction+eps)-torch.log(1.0-neg_prediction+eps))+beta*dkl\n",
    "        \n",
    "        # record loss history\n",
    "        #print(\"batch_id: \" + str(batch_id) + \" loss: \" + str(loss.item()))\n",
    "        if not torch.isinf(loss.data) and not torch.isnan(loss.data):\n",
    "            losses.append(float(loss.item()))\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Iteration %d,\\tloss: [%.4f], time: [%.1fs]' % (epoch_id, np.mean(np.array(losses)), time() - t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, groups_to_test, Ks, trainRatings, num_items):\n",
    "    model.eval()\n",
    "    t2 = time()\n",
    "    ret = test(model, groups_to_test, Ks, trainRatings, num_items) #See batch_test\n",
    "\n",
    "    print('\\t Evaluation done [%.1f s]' % (time() - t2))\n",
    "    for i, k in enumerate(Ks):\n",
    "        print('\\t\\t @%d: HR = %.4f, NDCG = %.4f, Rec = %.4f' % (k, ret['hit_ratio'][i], ret['ndcg'][i], ret['recall'][i]))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meetup.ca 80 256\n"
     ]
    }
   ],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_groups: 607 num_users: 56878 num_items: 1490\n"
     ]
    }
   ],
   "source": [
    "dataset = GDataset(config.user_dataset, config.group_dataset, config.user_in_group_path, 1)\n",
    "num_groups, num_users, num_items = dataset.num_groups, dataset.num_users, dataset.num_items\n",
    "print(\"num_groups: \"+str(num_groups)+\" num_users: \"+str(num_users)+\" num_items: \"+str(num_items))\n",
    "gu_dict = dataset.gu_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_warm = dataset.load_rating_file_as_dict(config.group_dataset + \".test.rating_warm\")\n",
    "test_cold = dataset.load_rating_file_as_dict(config.group_dataset + \".test.rating_cold\")\n",
    "#ret = evaluation(agree, test_warm, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "#ret = evaluation(agree, test_cold, config.topK[:2], dataset.group_trainRatings, dataset.num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGREE: embedding size 32, run Iteration: 80, #neg: 4\n",
      "Iteration 0,\tloss: [1.1518], time: [9.4s]\n",
      "Iteration 1,\tloss: [0.8803], time: [8.3s]\n",
      "Iteration 2,\tloss: [0.6174], time: [8.3s]\n",
      "Iteration 3,\tloss: [0.3784], time: [8.3s]\n",
      "Iteration 4,\tloss: [0.2545], time: [8.2s]\n",
      "Iteration 5,\tloss: [0.1856], time: [8.3s]\n",
      "Iteration 6,\tloss: [0.1390], time: [8.7s]\n",
      "Iteration 7,\tloss: [0.1099], time: [8.3s]\n",
      "Iteration 8,\tloss: [0.0888], time: [8.2s]\n",
      "Iteration 9,\tloss: [0.0738], time: [8.3s]\n",
      "Iteration 10,\tloss: [0.0647], time: [8.5s]\n",
      "Iteration 11,\tloss: [0.0631], time: [8.3s]\n",
      "Iteration 12,\tloss: [0.0507], time: [8.2s]\n",
      "Iteration 13,\tloss: [0.0386], time: [8.1s]\n",
      "Iteration 14,\tloss: [0.0380], time: [8.1s]\n",
      "Iteration 15,\tloss: [0.0416], time: [8.2s]\n",
      "Iteration 16,\tloss: [0.0407], time: [8.2s]\n",
      "Iteration 17,\tloss: [0.0381], time: [8.1s]\n",
      "Iteration 18,\tloss: [0.0394], time: [8.2s]\n",
      "Iteration 19,\tloss: [0.0410], time: [8.1s]\n",
      "Iteration 20,\tloss: [73.1183], time: [8.1s]\n",
      "Iteration 21,\tloss: [40.4427], time: [8.1s]\n",
      "\t Evaluation done [24.8 s]\n",
      "\t\t @5: HR = 0.0923, NDCG = 0.0522, Rec = 0.0564\n",
      "\t\t @10: HR = 0.2154, NDCG = 0.0965, Rec = 0.1269\n",
      "\t Evaluation done [8.4 s]\n",
      "\t\t @5: HR = 0.1591, NDCG = 0.0860, Rec = 0.0777\n",
      "\t\t @10: HR = 0.2727, NDCG = 0.1255, Rec = 0.1364\n",
      "Iteration 22,\tloss: [24.4049], time: [8.5s]\n",
      "\t Evaluation done [25.7 s]\n",
      "\t\t @5: HR = 0.1077, NDCG = 0.0471, Rec = 0.0795\n",
      "\t\t @10: HR = 0.3000, NDCG = 0.1127, Rec = 0.1936\n",
      "\t Evaluation done [8.8 s]\n",
      "\t\t @5: HR = 0.2500, NDCG = 0.1689, Rec = 0.1326\n",
      "\t\t @10: HR = 0.2955, NDCG = 0.1941, Rec = 0.1742\n",
      "Iteration 23,\tloss: [7.6812], time: [8.3s]\n",
      "\t Evaluation done [25.0 s]\n",
      "\t\t @5: HR = 0.1154, NDCG = 0.0757, Rec = 0.0808\n",
      "\t\t @10: HR = 0.2615, NDCG = 0.1272, Rec = 0.1782\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.2500, NDCG = 0.1332, Rec = 0.1155\n",
      "\t\t @10: HR = 0.3182, NDCG = 0.1751, Rec = 0.1667\n",
      "Iteration 24,\tloss: [3.4169], time: [8.1s]\n",
      "\t Evaluation done [25.3 s]\n",
      "\t\t @5: HR = 0.1538, NDCG = 0.0807, Rec = 0.0833\n",
      "\t\t @10: HR = 0.2846, NDCG = 0.1318, Rec = 0.1859\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.2273, NDCG = 0.1153, Rec = 0.1080\n",
      "\t\t @10: HR = 0.3409, NDCG = 0.1788, Rec = 0.1875\n",
      "Iteration 25,\tloss: [2.7113], time: [8.1s]\n",
      "\t Evaluation done [24.8 s]\n",
      "\t\t @5: HR = 0.1538, NDCG = 0.0831, Rec = 0.0923\n",
      "\t\t @10: HR = 0.2923, NDCG = 0.1337, Rec = 0.1744\n",
      "\t Evaluation done [8.4 s]\n",
      "\t\t @5: HR = 0.2045, NDCG = 0.1259, Rec = 0.1231\n",
      "\t\t @10: HR = 0.3864, NDCG = 0.1903, Rec = 0.2045\n",
      "Iteration 26,\tloss: [2.7640], time: [8.1s]\n",
      "\t Evaluation done [25.2 s]\n",
      "\t\t @5: HR = 0.1308, NDCG = 0.0685, Rec = 0.0859\n",
      "\t\t @10: HR = 0.2615, NDCG = 0.1140, Rec = 0.1603\n",
      "\t Evaluation done [8.5 s]\n",
      "\t\t @5: HR = 0.2500, NDCG = 0.1571, Rec = 0.1345\n",
      "\t\t @10: HR = 0.4091, NDCG = 0.2110, Rec = 0.2045\n",
      "Iteration 27,\tloss: [1.6443], time: [8.3s]\n",
      "\t Evaluation done [25.3 s]\n",
      "\t\t @5: HR = 0.1000, NDCG = 0.0620, Rec = 0.0744\n",
      "\t\t @10: HR = 0.2308, NDCG = 0.1036, Rec = 0.1577\n",
      "\t Evaluation done [9.3 s]\n",
      "\t\t @5: HR = 0.2273, NDCG = 0.1681, Rec = 0.1080\n",
      "\t\t @10: HR = 0.3182, NDCG = 0.2118, Rec = 0.1742\n",
      "Iteration 28,\tloss: [1.9461], time: [8.4s]\n",
      "\t Evaluation done [25.3 s]\n",
      "\t\t @5: HR = 0.1462, NDCG = 0.0825, Rec = 0.0872\n",
      "\t\t @10: HR = 0.2769, NDCG = 0.1276, Rec = 0.1756\n",
      "\t Evaluation done [8.5 s]\n",
      "\t\t @5: HR = 0.1818, NDCG = 0.0990, Rec = 0.0795\n",
      "\t\t @10: HR = 0.3409, NDCG = 0.1764, Rec = 0.2027\n",
      "Iteration 29,\tloss: [1.1121], time: [8.5s]\n",
      "\t Evaluation done [25.1 s]\n",
      "\t\t @5: HR = 0.1231, NDCG = 0.0677, Rec = 0.0885\n",
      "\t\t @10: HR = 0.2615, NDCG = 0.1151, Rec = 0.1795\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.2500, NDCG = 0.1450, Rec = 0.1136\n",
      "\t\t @10: HR = 0.3182, NDCG = 0.1818, Rec = 0.1818\n",
      "Iteration 30,\tloss: [1.9315], time: [8.1s]\n",
      "\t Evaluation done [25.3 s]\n",
      "\t\t @5: HR = 0.1615, NDCG = 0.0836, Rec = 0.0987\n",
      "\t\t @10: HR = 0.3077, NDCG = 0.1384, Rec = 0.2064\n",
      "\t Evaluation done [8.4 s]\n",
      "\t\t @5: HR = 0.2045, NDCG = 0.1376, Rec = 0.0985\n",
      "\t\t @10: HR = 0.4091, NDCG = 0.2107, Rec = 0.2027\n",
      "Iteration 31,\tloss: [1.1088], time: [8.2s]\n",
      "\t Evaluation done [25.0 s]\n",
      "\t\t @5: HR = 0.1231, NDCG = 0.0672, Rec = 0.0731\n",
      "\t\t @10: HR = 0.2538, NDCG = 0.1164, Rec = 0.1744\n",
      "\t Evaluation done [8.4 s]\n",
      "\t\t @5: HR = 0.2500, NDCG = 0.1440, Rec = 0.1269\n",
      "\t\t @10: HR = 0.4091, NDCG = 0.1953, Rec = 0.1970\n",
      "Iteration 32,\tloss: [1.1320], time: [8.5s]\n",
      "\t Evaluation done [25.2 s]\n",
      "\t\t @5: HR = 0.1154, NDCG = 0.0609, Rec = 0.0859\n",
      "\t\t @10: HR = 0.2308, NDCG = 0.1027, Rec = 0.1628\n",
      "\t Evaluation done [8.4 s]\n",
      "\t\t @5: HR = 0.2273, NDCG = 0.1157, Rec = 0.1080\n",
      "\t\t @10: HR = 0.4318, NDCG = 0.1989, Rec = 0.2348\n",
      "Iteration 33,\tloss: [1.2341], time: [8.2s]\n",
      "\t Evaluation done [24.9 s]\n",
      "\t\t @5: HR = 0.0923, NDCG = 0.0512, Rec = 0.0628\n",
      "\t\t @10: HR = 0.2615, NDCG = 0.1064, Rec = 0.1654\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.2955, NDCG = 0.1585, Rec = 0.1515\n",
      "\t\t @10: HR = 0.3864, NDCG = 0.1995, Rec = 0.1989\n",
      "Iteration 34,\tloss: [1.1930], time: [8.2s]\n",
      "\t Evaluation done [24.8 s]\n",
      "\t\t @5: HR = 0.0692, NDCG = 0.0462, Rec = 0.0603\n",
      "\t\t @10: HR = 0.1615, NDCG = 0.0753, Rec = 0.1167\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.2500, NDCG = 0.1492, Rec = 0.1098\n",
      "\t\t @10: HR = 0.3182, NDCG = 0.1904, Rec = 0.1742\n",
      "Iteration 35,\tloss: [0.9110], time: [8.2s]\n",
      "\t Evaluation done [24.8 s]\n",
      "\t\t @5: HR = 0.0385, NDCG = 0.0253, Rec = 0.0295\n",
      "\t\t @10: HR = 0.1615, NDCG = 0.0650, Rec = 0.1179\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.2727, NDCG = 0.1488, Rec = 0.1250\n",
      "\t\t @10: HR = 0.3182, NDCG = 0.1889, Rec = 0.1799\n",
      "Iteration 36,\tloss: [0.9701], time: [8.2s]\n",
      "\t Evaluation done [25.5 s]\n",
      "\t\t @5: HR = 0.0615, NDCG = 0.0399, Rec = 0.0423\n",
      "\t\t @10: HR = 0.2077, NDCG = 0.0878, Rec = 0.1282\n",
      "\t Evaluation done [8.5 s]\n",
      "\t\t @5: HR = 0.2500, NDCG = 0.1264, Rec = 0.1004\n",
      "\t\t @10: HR = 0.3409, NDCG = 0.1822, Rec = 0.1856\n",
      "Iteration 37,\tloss: [1.0959], time: [8.6s]\n",
      "\t Evaluation done [26.2 s]\n",
      "\t\t @5: HR = 0.0846, NDCG = 0.0428, Rec = 0.0603\n",
      "\t\t @10: HR = 0.1923, NDCG = 0.0801, Rec = 0.1269\n",
      "\t Evaluation done [8.4 s]\n",
      "\t\t @5: HR = 0.2045, NDCG = 0.1038, Rec = 0.0871\n",
      "\t\t @10: HR = 0.2955, NDCG = 0.1513, Rec = 0.1515\n",
      "Iteration 38,\tloss: [0.9796], time: [8.2s]\n",
      "\t Evaluation done [24.7 s]\n",
      "\t\t @5: HR = 0.1077, NDCG = 0.0543, Rec = 0.0628\n",
      "\t\t @10: HR = 0.2231, NDCG = 0.0934, Rec = 0.1551\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.2045, NDCG = 0.1111, Rec = 0.0795\n",
      "\t\t @10: HR = 0.3182, NDCG = 0.1609, Rec = 0.1458\n",
      "Iteration 39,\tloss: [0.7949], time: [8.2s]\n",
      "\t Evaluation done [26.1 s]\n",
      "\t\t @5: HR = 0.1077, NDCG = 0.0524, Rec = 0.0641\n",
      "\t\t @10: HR = 0.2231, NDCG = 0.0949, Rec = 0.1500\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.2045, NDCG = 0.1329, Rec = 0.1326\n",
      "\t\t @10: HR = 0.2955, NDCG = 0.1696, Rec = 0.1799\n",
      "Iteration 40,\tloss: [0.9184], time: [8.2s]\n",
      "\t Evaluation done [24.9 s]\n",
      "\t\t @5: HR = 0.0538, NDCG = 0.0284, Rec = 0.0308\n",
      "\t\t @10: HR = 0.2692, NDCG = 0.0995, Rec = 0.1654\n",
      "\t Evaluation done [8.4 s]\n",
      "\t\t @5: HR = 0.2955, NDCG = 0.1811, Rec = 0.1269\n",
      "\t\t @10: HR = 0.3864, NDCG = 0.2278, Rec = 0.1989\n",
      "Iteration 41,\tloss: [0.8057], time: [8.2s]\n",
      "\t Evaluation done [24.9 s]\n",
      "\t\t @5: HR = 0.1000, NDCG = 0.0554, Rec = 0.0603\n",
      "\t\t @10: HR = 0.1923, NDCG = 0.0865, Rec = 0.1128\n",
      "\t Evaluation done [8.5 s]\n",
      "\t\t @5: HR = 0.2955, NDCG = 0.1680, Rec = 0.1364\n",
      "\t\t @10: HR = 0.3182, NDCG = 0.1856, Rec = 0.1591\n",
      "Iteration 42,\tloss: [0.7177], time: [8.5s]\n",
      "\t Evaluation done [25.0 s]\n",
      "\t\t @5: HR = 0.1077, NDCG = 0.0538, Rec = 0.0718\n",
      "\t\t @10: HR = 0.2385, NDCG = 0.0974, Rec = 0.1641\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.1818, NDCG = 0.1285, Rec = 0.0985\n",
      "\t\t @10: HR = 0.3182, NDCG = 0.1773, Rec = 0.1648\n",
      "Iteration 43,\tloss: [0.7908], time: [8.2s]\n",
      "\t Evaluation done [24.8 s]\n",
      "\t\t @5: HR = 0.0846, NDCG = 0.0478, Rec = 0.0615\n",
      "\t\t @10: HR = 0.2231, NDCG = 0.0945, Rec = 0.1487\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.3182, NDCG = 0.1848, Rec = 0.1402\n",
      "\t\t @10: HR = 0.3864, NDCG = 0.2206, Rec = 0.1894\n",
      "Iteration 44,\tloss: [0.7573], time: [8.2s]\n",
      "\t Evaluation done [24.8 s]\n",
      "\t\t @5: HR = 0.1308, NDCG = 0.0675, Rec = 0.0821\n",
      "\t\t @10: HR = 0.2308, NDCG = 0.0998, Rec = 0.1423\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.1591, NDCG = 0.0931, Rec = 0.0682\n",
      "\t\t @10: HR = 0.3182, NDCG = 0.1466, Rec = 0.1402\n",
      "Iteration 45,\tloss: [0.7006], time: [8.2s]\n",
      "\t Evaluation done [24.8 s]\n",
      "\t\t @5: HR = 0.1308, NDCG = 0.0721, Rec = 0.0744\n",
      "\t\t @10: HR = 0.2385, NDCG = 0.1123, Rec = 0.1513\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.2500, NDCG = 0.1590, Rec = 0.1174\n",
      "\t\t @10: HR = 0.3409, NDCG = 0.2020, Rec = 0.1894\n",
      "Iteration 46,\tloss: [0.8200], time: [8.2s]\n",
      "\t Evaluation done [25.2 s]\n",
      "\t\t @5: HR = 0.1077, NDCG = 0.0503, Rec = 0.0667\n",
      "\t\t @10: HR = 0.2538, NDCG = 0.1020, Rec = 0.1859\n",
      "\t Evaluation done [8.6 s]\n",
      "\t\t @5: HR = 0.2727, NDCG = 0.1546, Rec = 0.1345\n",
      "\t\t @10: HR = 0.3864, NDCG = 0.1990, Rec = 0.1875\n",
      "Iteration 47,\tloss: [0.5753], time: [8.4s]\n",
      "\t Evaluation done [25.1 s]\n",
      "\t\t @5: HR = 0.1154, NDCG = 0.0528, Rec = 0.0705\n",
      "\t\t @10: HR = 0.2154, NDCG = 0.0881, Rec = 0.1436\n",
      "\t Evaluation done [8.5 s]\n",
      "\t\t @5: HR = 0.2273, NDCG = 0.1506, Rec = 0.1136\n",
      "\t\t @10: HR = 0.3636, NDCG = 0.1970, Rec = 0.2008\n",
      "Iteration 48,\tloss: [0.6198], time: [8.2s]\n",
      "\t Evaluation done [25.2 s]\n",
      "\t\t @5: HR = 0.0846, NDCG = 0.0433, Rec = 0.0590\n",
      "\t\t @10: HR = 0.2154, NDCG = 0.0878, Rec = 0.1321\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.2045, NDCG = 0.1190, Rec = 0.0777\n",
      "\t\t @10: HR = 0.2955, NDCG = 0.1687, Rec = 0.1326\n",
      "Iteration 49,\tloss: [0.6651], time: [8.2s]\n",
      "\t Evaluation done [24.7 s]\n",
      "\t\t @5: HR = 0.0846, NDCG = 0.0417, Rec = 0.0526\n",
      "\t\t @10: HR = 0.2077, NDCG = 0.0851, Rec = 0.1410\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.2045, NDCG = 0.1174, Rec = 0.1155\n",
      "\t\t @10: HR = 0.3409, NDCG = 0.1785, Rec = 0.2216\n",
      "Iteration 50,\tloss: [0.5734], time: [8.2s]\n",
      "\t Evaluation done [24.7 s]\n",
      "\t\t @5: HR = 0.0846, NDCG = 0.0388, Rec = 0.0551\n",
      "\t\t @10: HR = 0.1846, NDCG = 0.0736, Rec = 0.1179\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.2045, NDCG = 0.1289, Rec = 0.1061\n",
      "\t\t @10: HR = 0.2955, NDCG = 0.1747, Rec = 0.1648\n",
      "Iteration 51,\tloss: [0.5980], time: [8.2s]\n",
      "\t Evaluation done [24.8 s]\n",
      "\t\t @5: HR = 0.1000, NDCG = 0.0413, Rec = 0.0577\n",
      "\t\t @10: HR = 0.3000, NDCG = 0.1124, Rec = 0.2000\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.2955, NDCG = 0.2085, Rec = 0.1420\n",
      "\t\t @10: HR = 0.3864, NDCG = 0.2490, Rec = 0.2008\n",
      "Iteration 52,\tloss: [0.6436], time: [8.2s]\n",
      "\t Evaluation done [24.7 s]\n",
      "\t\t @5: HR = 0.1154, NDCG = 0.0622, Rec = 0.0679\n",
      "\t\t @10: HR = 0.2231, NDCG = 0.1009, Rec = 0.1372\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.2273, NDCG = 0.1426, Rec = 0.1042\n",
      "\t\t @10: HR = 0.3409, NDCG = 0.1976, Rec = 0.1799\n",
      "Iteration 53,\tloss: [0.5133], time: [8.4s]\n",
      "\t Evaluation done [25.2 s]\n",
      "\t\t @5: HR = 0.0923, NDCG = 0.0428, Rec = 0.0628\n",
      "\t\t @10: HR = 0.1923, NDCG = 0.0775, Rec = 0.1154\n",
      "\t Evaluation done [8.5 s]\n",
      "\t\t @5: HR = 0.1818, NDCG = 0.1381, Rec = 0.1061\n",
      "\t\t @10: HR = 0.3409, NDCG = 0.1943, Rec = 0.1686\n",
      "Iteration 54,\tloss: [0.6134], time: [8.3s]\n",
      "\t Evaluation done [25.1 s]\n",
      "\t\t @5: HR = 0.1000, NDCG = 0.0557, Rec = 0.0538\n",
      "\t\t @10: HR = 0.2000, NDCG = 0.0898, Rec = 0.1321\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.1818, NDCG = 0.1048, Rec = 0.0833\n",
      "\t\t @10: HR = 0.3409, NDCG = 0.1645, Rec = 0.1534\n",
      "Iteration 55,\tloss: [0.5597], time: [8.2s]\n",
      "\t Evaluation done [24.8 s]\n",
      "\t\t @5: HR = 0.1077, NDCG = 0.0599, Rec = 0.0577\n",
      "\t\t @10: HR = 0.2385, NDCG = 0.1033, Rec = 0.1474\n",
      "\t Evaluation done [8.3 s]\n",
      "\t\t @5: HR = 0.2273, NDCG = 0.1522, Rec = 0.1004\n",
      "\t\t @10: HR = 0.2727, NDCG = 0.1809, Rec = 0.1364\n",
      "Iteration 56,\tloss: [0.5788], time: [8.2s]\n",
      "\t Evaluation done [24.9 s]\n",
      "\t\t @5: HR = 0.1000, NDCG = 0.0527, Rec = 0.0590\n",
      "\t\t @10: HR = 0.3000, NDCG = 0.1199, Rec = 0.1885\n",
      "\t Evaluation done [8.4 s]\n",
      "\t\t @5: HR = 0.2273, NDCG = 0.1538, Rec = 0.0758\n",
      "\t\t @10: HR = 0.3182, NDCG = 0.1884, Rec = 0.1288\n",
      "Iteration 57,\tloss: [0.6168], time: [8.2s]\n",
      "\t Evaluation done [25.1 s]\n",
      "\t\t @5: HR = 0.0923, NDCG = 0.0521, Rec = 0.0551\n",
      "\t\t @10: HR = 0.2308, NDCG = 0.0975, Rec = 0.1321\n",
      "\t Evaluation done [8.4 s]\n",
      "\t\t @5: HR = 0.2273, NDCG = 0.1466, Rec = 0.1061\n",
      "\t\t @10: HR = 0.3636, NDCG = 0.1927, Rec = 0.1667\n",
      "Iteration 58,\tloss: [0.7263], time: [8.2s]\n",
      "\t Evaluation done [25.3 s]\n",
      "\t\t @5: HR = 0.1077, NDCG = 0.0593, Rec = 0.0628\n",
      "\t\t @10: HR = 0.2231, NDCG = 0.1006, Rec = 0.1385\n",
      "\t Evaluation done [8.4 s]\n",
      "\t\t @5: HR = 0.1818, NDCG = 0.1253, Rec = 0.0625\n",
      "\t\t @10: HR = 0.2955, NDCG = 0.1706, Rec = 0.1402\n",
      "Iteration 59,\tloss: [0.4675], time: [8.2s]\n",
      "\t Evaluation done [24.9 s]\n",
      "\t\t @5: HR = 0.1000, NDCG = 0.0498, Rec = 0.0641\n",
      "\t\t @10: HR = 0.1923, NDCG = 0.0812, Rec = 0.1154\n",
      "\t Evaluation done [8.4 s]\n",
      "\t\t @5: HR = 0.2727, NDCG = 0.1584, Rec = 0.1117\n",
      "\t\t @10: HR = 0.3409, NDCG = 0.1953, Rec = 0.1610\n",
      "Iteration 60,\tloss: [0.4574], time: [8.2s]\n",
      "\t Evaluation done [25.0 s]\n",
      "\t\t @5: HR = 0.1462, NDCG = 0.0688, Rec = 0.0821\n",
      "\t\t @10: HR = 0.2462, NDCG = 0.1037, Rec = 0.1487\n",
      "\t Evaluation done [8.8 s]\n",
      "\t\t @5: HR = 0.2727, NDCG = 0.1670, Rec = 0.1155\n",
      "\t\t @10: HR = 0.3182, NDCG = 0.1969, Rec = 0.1572\n",
      "Iteration 61,\tloss: [0.4493], time: [8.5s]\n",
      "\t Evaluation done [27.5 s]\n",
      "\t\t @5: HR = 0.1077, NDCG = 0.0537, Rec = 0.0577\n",
      "\t\t @10: HR = 0.2077, NDCG = 0.0873, Rec = 0.1218\n",
      "\t Evaluation done [9.5 s]\n",
      "\t\t @5: HR = 0.1364, NDCG = 0.0909, Rec = 0.0549\n",
      "\t\t @10: HR = 0.2500, NDCG = 0.1346, Rec = 0.1098\n",
      "Iteration 62,\tloss: [0.5412], time: [9.4s]\n",
      "\t Evaluation done [28.4 s]\n",
      "\t\t @5: HR = 0.1231, NDCG = 0.0648, Rec = 0.0769\n",
      "\t\t @10: HR = 0.2462, NDCG = 0.1088, Rec = 0.1449\n",
      "\t Evaluation done [9.2 s]\n",
      "\t\t @5: HR = 0.2045, NDCG = 0.1365, Rec = 0.0871\n",
      "\t\t @10: HR = 0.3182, NDCG = 0.1940, Rec = 0.1534\n",
      "Iteration 63,\tloss: [0.4312], time: [8.5s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d0cd8c2c9e6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;31m#ret = evaluation(agree, dataset.group_testRatings, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_warm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_trainRatings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mcur_checkpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hit_ratio'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_cold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_trainRatings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ea7780676338>\u001b[0m in \u001b[0;36mevaluation\u001b[1;34m(model, groups_to_test, Ks, trainRatings, num_items)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups_to_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainRatings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#See batch_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\t Evaluation done [%.1f s]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PythonProjects\\AGR\\batch_test.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(model, groups_to_test, Ks, group_trainRatings, num_items, drop_flag, batch_test_flag)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;31m#count = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mg_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_one_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_trainRatings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_groups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m         \u001b[1;31m#for re in batch_result:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PythonProjects\\AGR\\batch_test.py\u001b[0m in \u001b[0;36mtest_one_group\u001b[1;34m(x, model, Ks, group_trainRatings, group_testRatings, num_items)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[0mitem_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0mrating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[0mrating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrating\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;31m#rating, _ = model(group_var, item_var, is_training=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch171\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PythonProjects\\AGR\\model\\agree_re.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, group_inputs, item_inputs, is_training)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgroup_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0mmembers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_member_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0muidx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmembers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m             \u001b[0mmembers_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muserembeds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muidx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agree = VARGR_NCF(num_users, num_items, num_groups, config.embedding_size, gu_dict, config.drop_ratio).cuda()\n",
    "best_checkpoint = -1.0\n",
    "best_weights_path = None\n",
    "for num_negatives in config.num_negatives:\n",
    "    dataset.num_negatives = num_negatives\n",
    "    print(\"AGREE: embedding size %d, run Iteration: %d, #neg: %d\" %(config.embedding_size, config.epoch, num_negatives))\n",
    "    # train the model\n",
    "    now = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    for epoch in range(config.epoch): \n",
    "        training(agree, dataset.get_group_dataloader(config.batch_size), epoch, config)\n",
    "        \n",
    "\n",
    "        # Evaluation\n",
    "        if epoch > WU_point:\n",
    "\n",
    "            #ret = evaluation(agree, dataset.group_testRatings, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "            ret = evaluation(agree, test_warm, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "            cur_checkpoint = ret['hit_ratio'][1]\n",
    "            ret = evaluation(agree, test_cold, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "            current_weights_path = 'weights/VarGrNCF_'+str(config.dataset)+\"_\"+str(config.embedding_size)+\"_\"+str(config.lr[0])+'_'+str(num_negatives)+'_'+str(epoch)\n",
    "            torch.save(agree.state_dict(), current_weights_path)\n",
    "            if best_checkpoint <= cur_checkpoint:\n",
    "                best_weights_path = current_weights_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agree = VARGR_NCF(num_users, num_items, num_groups, config.embedding_size, gu_dict, config.drop_ratio).cuda()\n",
    "agree.load_state_dict(torch.load(best_weights_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print('total')\n",
    "ret = evaluation(agree, dataset.group_testRatings, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "print('cold')\n",
    "ret = evaluation(agree, test_cold, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "print('warm')\n",
    "ret = evaluation(agree, test_warm, config.topK[:2], dataset.group_trainRatings, dataset.num_items)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For ablation\n",
    "agree = VARGR_NCF(num_users, num_items, num_groups, config.embedding_size, gu_dict, config.drop_ratio).cuda()\n",
    "agree.load_state_dict(torch.load('weights/VarGrNCF_meetup.ca_32_0.01_4_57'))\n",
    "for _ in range(10):\n",
    "    print('warm')\n",
    "    ret = evaluation(agree, test_warm, config.topK[:2], dataset.group_trainRatings, dataset.num_items)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agree.load_state_dict(torch.load('weights/VarGrNCF_meetup.ca_32_0.01_4_57'))\n",
    "print('total')\n",
    "ret = evaluation(agree, dataset.group_testRatings, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "print('cold')\n",
    "ret = evaluation(agree, test_cold, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "print('warm')\n",
    "ret = evaluation(agree, test_warm, config.topK[:2], dataset.group_trainRatings, dataset.num_items)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    print('total')\n",
    "    ret = evaluation(agree, dataset.group_testRatings, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "    print('cold')\n",
    "    ret = evaluation(agree, test_cold, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "    print('warm')\n",
    "    ret = evaluation(agree, test_warm, config.topK[:2], dataset.group_trainRatings, dataset.num_items)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utest_one_group(x, model, Ks, group_trainRatings, group_testRatings, num_items,thresholds, num_repeat, tor):\n",
    "    #rating = x[0]\n",
    "    g = x #group 1개 들어옴\n",
    "\n",
    "    try:\n",
    "        training_items = group_trainRatings[g]\n",
    "    except Exception:\n",
    "        training_items = []\n",
    "\n",
    "    group_pos_test = group_testRatings[g]\n",
    "\n",
    "    all_items = set(range(num_items))\n",
    "\n",
    "    test_items = list(all_items-set(training_items))\n",
    "    one_group_batch = np.full(len(test_items),g)\n",
    "    group_var = torch.LongTensor(one_group_batch)\n",
    "    item_var = torch.LongTensor(test_items)\n",
    "\n",
    "    rating_mean = 0\n",
    "    rating_variance = 0\n",
    "    for _ in range(num_repeat):\n",
    "        rating = model(group_var, item_var).detach().cpu()\n",
    "        rating_mean += rating\n",
    "        rating_variance += torch.square(rating)\n",
    "    rating_mean = rating_mean / num_repeat\n",
    "    rating_variance = rating_variance/num_repeat - torch.square(rating_mean)\n",
    "\n",
    "    \n",
    "    EPS = 1e-8\n",
    "    entropy = - rating_mean * torch.log(rating_mean+EPS)- (1.0-rating_mean)*torch.log(1.0-rating_mean+EPS)\n",
    "    #entropy = 4*rating_mean*(1.0-rating_mean)\n",
    "    #entropy = (rating_variance-rating_variance.min())/((rating_variance.max()-rating_variance.min()+1e-8))\n",
    "    \n",
    "    \n",
    "    #ipdb.set_trace()\n",
    "    \n",
    "    results = []\n",
    "    for threshold in thresholds:\n",
    "        indices = torch.where(entropy <=threshold)[0]\n",
    "\n",
    "        utest_items = [test_items[i] for i in indices.tolist()]\n",
    "        urating = torch.index_select(rating_mean, 0, indices)\n",
    "        \n",
    "        pos_urating = torch.where(urating >=tor)[0].tolist()\n",
    "        \n",
    "        urating = urating.cpu().numpy()\n",
    "        pt = len(set(pos_urating).intersection(group_pos_test))\n",
    "        nt = len(urating) - len(pos_urating) - (len(group_pos_test)-pt)\n",
    "        #print()\n",
    "        acc = (pt+nt)/len(urating)\n",
    "\n",
    "        r, auc = ranklist_by_sorted(group_pos_test, utest_items, urating, Ks)\n",
    "        ret = get_performance(group_pos_test, r, auc, Ks)\n",
    "        ret['acc'] = acc\n",
    "        results.append(ret)\n",
    "    return results\n",
    "\n",
    "def utest(model, groups_to_test, Ks, group_trainRatings, num_items, batch_test_flag = False, thresholds=[1.0,], num_repeat=1, tor=0.9):\n",
    "    result = {}\n",
    "    for threshold in thresholds:\n",
    "        result[threshold] = {'precision': np.zeros(len(Ks)), 'recall': np.zeros(len(Ks)), 'ndcg': np.zeros(len(Ks)),\n",
    "                              'hit_ratio': np.zeros(len(Ks)), 'auc': 0., 'acc': 0.}\n",
    "\n",
    "\n",
    "    test_groups = groups_to_test\n",
    "    n_test_groups = len(test_groups)\n",
    "    #n_group_batchs = n_test_groups // g_batch_size + 1\n",
    "    #print(n_group_batchs)\n",
    "    #count = 0\n",
    "    for g_id in test_groups:\n",
    "        re = utest_one_group(g_id, model, Ks, group_trainRatings, test_groups, num_items,thresholds=thresholds, num_repeat=num_repeat, tor=tor)\n",
    "        #for re in batch_result:\n",
    "        for i, threshold in enumerate(thresholds):\n",
    "            result[threshold]['precision'] += re[i]['precision']/n_test_groups\n",
    "            result[threshold]['recall'] += re[i]['recall']/n_test_groups\n",
    "            result[threshold]['ndcg'] += re[i]['ndcg']/n_test_groups\n",
    "            result[threshold]['hit_ratio'] += re[i]['hit_ratio']/n_test_groups\n",
    "            result[threshold]['auc'] += re[i]['auc']/n_test_groups\n",
    "            result[threshold]['acc'] += re[i]['acc']/n_test_groups\n",
    "        #print(re['hit_ratio'])\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "def uevaluation(model, groups_to_test, Ks, trainRatings, num_items, thresholds=[1.0,], num_repeat=1, tor = 0.9):\n",
    "    model.eval()\n",
    "    t2 = time()\n",
    "\n",
    "    ret = utest(model, groups_to_test, Ks, trainRatings, num_items,thresholds=thresholds, num_repeat=num_repeat, tor=tor) #See batch_test for test()\n",
    "\n",
    "    print('\\t Evaluation done [%.1f s]' % (time() - t2))\n",
    "    for threshold in thresholds:\n",
    "        print('Threshold:', threshold)\n",
    "        for i, k in enumerate(Ks):\n",
    "            print('\\t\\t @%d: HR = %.4f, NDCG = %.4f, Rec = %.4f, Precision = %.4f, AUC = %.4f' % (k, ret[threshold]['hit_ratio'][i], ret[threshold]['ndcg'][i], ret[threshold]['recall'][i], ret[threshold]['precision'][i], ret[threshold]['acc']))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "agree = VARGR_NCF(num_users, num_items, num_groups, config.embedding_size, gu_dict, config.drop_ratio).cuda()\n",
    "agree.load_state_dict(torch.load('weights/VarGrNCF_meetup.ca_32_0.01_4_57'))\n",
    "for tor in [0.5,]:\n",
    "    print(tor)\n",
    "    tttt = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    #print('total')\n",
    "    #ret_total = uevaluation(agree, dataset.group_testRatings, config.topK[:2], dataset.group_trainRatings, dataset.num_items, thresholds=tttt, num_repeat=5, tor=tor)\n",
    "    print('cold')\n",
    "    ret_cold = uevaluation(agree, test_cold, config.topK[:2], dataset.group_trainRatings, dataset.num_items, thresholds=tttt, num_repeat=5, tor=tor)\n",
    "    print('warm')\n",
    "    ret_warm = uevaluation(agree, test_warm, config.topK[:2], dataset.group_trainRatings, dataset.num_items, thresholds=tttt, num_repeat=5, tor=tor)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_g = torch.LongTensor(list(test_cold.keys()))\n",
    "print(test_g.shape)\n",
    "test_v = torch.zeros(test_g.shape).long()\n",
    "_ = agree(test_g, test_v)\n",
    "agree.eval()\n",
    "mu, sigma = agree.get_z_dist()\n",
    "mu = torch.norm(mu, dim=1)\n",
    "sigma = torch.norm(sigma, dim=1)\n",
    "print(torch.mean(mu), torch.mean(sigma))\n",
    "\n",
    "test_g = torch.LongTensor(list(test_warm.keys()))\n",
    "print(test_g.shape)\n",
    "test_v = torch.zeros(test_g.shape).long()\n",
    "_ = agree(test_g, test_v)\n",
    "agree.eval()\n",
    "mu, sigma = agree.get_z_dist()\n",
    "mu = torch.norm(mu, dim=1)\n",
    "sigma = torch.norm(sigma, dim=1)\n",
    "print(torch.mean(mu), torch.mean(sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = GDataset(config.user_dataset, config.group_dataset, config.user_in_group_path, 1)\n",
    "test_cold = dataset.load_rating_file_as_dict(config.group_dataset + \".test.rating_cold\")\n",
    "num_groups, num_users, num_items = dataset.num_groups, dataset.num_users, dataset.num_items\n",
    "agree = VARGR_NCF(num_users, num_items, num_groups, config.embedding_size, gu_dict, config.drop_ratio).cuda()\n",
    "agree.load_state_dict(torch.load('weights/VarGrNCF_meetup.ca_32_0.01_4_57'))\n",
    "\n",
    "test_g_cold = torch.LongTensor(list(test_cold.keys()))\n",
    "test_g_warm = torch.LongTensor(list(dataset.group_trainRatings.keys()))\n",
    "test_v = torch.zeros(test_g_cold.shape).long()\n",
    "agree.eval()\n",
    "_ = agree(test_g_cold, test_v)\n",
    "mu, sigma = agree.get_z_dist()\n",
    "\n",
    "q_std = np.sqrt(2/32)\n",
    "def KL(mu, sigma, mup, sigmap):\n",
    "    t = 2*torch.log(sigmap) - 2*torch.log(sigma) + (sigma**2)* (1/sigmap**2) + (1/sigmap**2)*((mu-mup)**2)-1\n",
    "    return t*0.5\n",
    "\n",
    "kl_loss_cold = []\n",
    "for i, g in enumerate(test_g_cold.detach().numpy()):\n",
    "    min_kl = 10000000.0\n",
    "    for gg in dataset.group_trainRatings:\n",
    "        sg = agree.groupembeds(torch.LongTensor([gg]))\n",
    "        kl = torch.sum(KL(sg.squeeze(0), (q_std*torch.ones(sg.shape)).squeeze(0).cuda(), mu[i], sigma[i])).item()\n",
    "        if kl <min_kl:\n",
    "            min_kl = kl\n",
    "\n",
    "    kl_loss_cold.append(min_kl)\n",
    "print(len(kl_loss_cold))\n",
    "print(np.mean(kl_loss_cold), np.std(kl_loss_cold)/np.sqrt(len(kl_loss_cold)))\n",
    "\n",
    "test_v = torch.zeros(test_g_warm.shape).long()\n",
    "agree.eval()\n",
    "_ = agree(test_g_warm, test_v)\n",
    "mu, sigma = agree.get_z_dist()\n",
    "\n",
    "kl_loss_warm = []\n",
    "for i, g in enumerate(test_g_warm.detach().numpy()):\n",
    "    min_kl = 10000000.0\n",
    "    sg = agree.groupembeds(torch.LongTensor([g]))\n",
    "    kl = torch.sum(KL(sg.squeeze(0), (q_std*torch.ones(sg.shape)).squeeze(0).cuda(), mu[i], sigma[i])).item()\n",
    "    if kl <min_kl:\n",
    "        min_kl = kl\n",
    "\n",
    "    kl_loss_warm.append(min_kl)\n",
    "print(len(kl_loss_warm))\n",
    "print(np.mean(kl_loss_warm), np.std(kl_loss_warm)/np.sqrt(len(kl_loss_warm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "font = {       'size'   : 11}\n",
    "matplotlib.rc('font', **font)\n",
    "fig, ax = plt.subplots(figsize=(2.5, 4))\n",
    "\n",
    "# plot violin plot\n",
    "'''\n",
    "axs[0].violinplot(kl_loss_warm,\n",
    "                  showmeans=False,\n",
    "                  showmedians=True)\n",
    "axs[0].set_title('Violin plot')\n",
    "axs[0].set_yscale('log')\n",
    "'''\n",
    "# plot box plot\n",
    "bp = ax.boxplot([kl_loss_warm, kl_loss_cold], patch_artist=True, labels=['Warm-start', 'Cold-start'], widths=(0.45,0.45))\n",
    "ax.set_title('VarGr_NCF')\n",
    "ax.set_yscale('log')\n",
    "for patch, color in zip(bp['boxes'], ['pink', 'lightblue']):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "#ax.set_xticks(['Warm-start', 'Cold-start'])\n",
    "ax.set_ylabel('KL loss', fontsize=14)\n",
    "ax.set_ylim([0.001, 50])\n",
    "\n",
    "'''\n",
    "# add x-tick labels\n",
    "plt.setp(axs, xticks=[y + 1 for y in range(len(all_data))],\n",
    "         xticklabels=['x1', 'x2', 'x3', 'x4'])\n",
    "'''\n",
    "#plt.savefig('figures/KL_VarNCF_MeetupCA.pdf', bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GDataset(config.user_dataset, config.group_dataset, config.user_in_group_path, 1)\n",
    "num_groups, num_users, num_items = dataset.num_groups, dataset.num_users, dataset.num_items\n",
    "agree = VARGR_NCF(num_users, num_items, num_groups, config.embedding_size, gu_dict, config.drop_ratio).cuda()\n",
    "agree.load_state_dict(torch.load('weights/VarGrNCF_meetup.ca_32_0.01_4_57'))\n",
    "\n",
    "new_group_list = []\n",
    "for g in dataset.group_testRatings.keys():\n",
    "    num_users = len(dataset.gu_dict[g])\n",
    "    if int(num_users*0.1) > 1:\n",
    "        for t in range(int(num_users*0.1), num_users, int(num_users*0.1)):\n",
    "            new_users = dataset.gu_dict[g][:t]\n",
    "            new_group_list.append(len(agree.group_member_dict))\n",
    "            agree.group_member_dict[len(agree.group_member_dict)] = new_users\n",
    "            \n",
    "\n",
    "test_g = torch.LongTensor(list(dataset.group_testRatings.keys())+new_group_list)\n",
    "test_v = torch.zeros(test_g.shape).long()\n",
    "_ = agree(test_g, test_v)\n",
    "agree.eval()\n",
    "mu, sigma = agree.get_z_dist()\n",
    "jaccard = {}\n",
    "mse = {}\n",
    "mas_var = {}\n",
    "most_similar_group = {}\n",
    "for i, g in enumerate(test_g.detach().numpy()):\n",
    "    if g in dataset.group_trainRatings:\n",
    "        sg = agree.groupembeds(torch.LongTensor([g]))\n",
    "        mse[g] = torch.sum(KL(sg.squeeze(0), (q_std*torch.ones(sg.shape)).squeeze(0).cuda(), mu[i], sigma[i]))\n",
    "        #mas_var[g] = torch.mean(sigma[i]**2)\n",
    "        jaccard[g] = 1.0\n",
    "    else:\n",
    "        max_g = None\n",
    "        max_jac = 0.0\n",
    "        for gg in dataset.group_trainRatings:\n",
    "            g_users = agree.group_member_dict[g]\n",
    "            gg_users = agree.group_member_dict[gg]\n",
    "            jac = len(set(g_users)&set(gg_users))/len(set(g_users)|set(gg_users))\n",
    "            if jac >= max_jac:\n",
    "                max_jac = jac\n",
    "                max_g = gg\n",
    "        sg = agree.groupembeds(torch.LongTensor([max_g]))\n",
    "        mse[g] = torch.sum(KL(sg.squeeze(0), (q_std*torch.ones(sg.shape)).squeeze(0).cuda(), mu[i], sigma[i]))\n",
    "        #mas_var[g] = torch.mean(sigma[i]**2)\n",
    "        jaccard[g] = max_jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_std = np.sqrt(2/32)\n",
    "def KL(mu, sigma, mup, sigmap):\n",
    "    t = 2*torch.log(sigmap) - 2*torch.log(sigma) + (sigma**2)* (1/sigmap**2) + (1/sigmap**2)*((mu-mup)**2)-1\n",
    "    return t*0.5\n",
    "for i, g in enumerate(test_g.detach().numpy()):\n",
    "    if g in dataset.group_trainRatings:\n",
    "        sg = agree.groupembeds(torch.LongTensor([g]))\n",
    "        mse[g] = torch.sum(KL(sg.squeeze(0), (q_std*torch.ones(sg.shape)).squeeze(0).cuda(), mu[i], sigma[i]))\n",
    "        #mas_var[g] = torch.mean(sigma[i]**2)\n",
    "        jaccard[g] = 1.0\n",
    "    else:\n",
    "        max_g = None\n",
    "        max_jac = 0.0\n",
    "        for gg in dataset.group_trainRatings:\n",
    "            g_users = agree.group_member_dict[g]\n",
    "            gg_users = agree.group_member_dict[gg]\n",
    "            jac = len(set(g_users)&set(gg_users))/len(set(g_users)|set(gg_users))\n",
    "            if jac >= max_jac:\n",
    "                max_jac = jac\n",
    "                max_g = gg\n",
    "        sg = agree.groupembeds(torch.LongTensor([max_g]))\n",
    "        mse[g] = torch.sum(KL(sg.squeeze(0), (q_std*torch.ones(sg.shape)).squeeze(0).cuda(), mu[i], sigma[i]))\n",
    "        #mas_var[g] = torch.mean(sigma[i]**2)\n",
    "        jaccard[g] = max_jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs_mse = {}\n",
    "avgs_var = {}\n",
    "idices = set()\n",
    "for g in jaccard:\n",
    "    idx = round(jaccard[g]*10)\n",
    "    idices.add(idx)\n",
    "    if idx not in avgs_mse:\n",
    "        avgs_mse[idx] = []\n",
    "        avgs_var[idx] = []\n",
    "    avgs_mse[idx].append(mse[g].item())\n",
    "    #avgs_var[idx].append(mas_var[g].item())\n",
    "final_mse = [0]*len(avgs_mse)\n",
    "final_var = [0]*len(avgs_mse)\n",
    "print(idices)\n",
    "for i in range(len(avgs_mse)):\n",
    "    final_mse[i] = np.mean(avgs_mse[i]) #sum(avgs_mse[i])/len(avgs_mse[i])\n",
    "    final_var[i] = np.std(avgs_mse[i])/np.sqrt(len(avgs_mse[i])) #sum(avgs_var[i])/len(avgs_var[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_mse, final_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "dataset = GDataset(config.user_dataset, config.group_dataset, config.user_in_group_path, 1)\n",
    "test_cold = dataset.load_rating_file_as_dict(config.group_dataset + \".test.rating_cold\")\n",
    "num_groups, num_users, num_items = dataset.num_groups, dataset.num_users, dataset.num_items\n",
    "agree = VARGR_NCF(num_users, num_items, num_groups, config.embedding_size, gu_dict, config.drop_ratio).cuda()\n",
    "agree.load_state_dict(torch.load('weights/VarGrNCF_meetup.ca_32_0.01_4_57'))\n",
    "\n",
    "cold_size = len(test_cold)\n",
    "test_g = torch.LongTensor(list(test_cold.keys())+list(dataset.group_trainRatings.keys()))\n",
    "test_v = torch.zeros(test_g.shape).long()\n",
    "agree.eval()\n",
    "_ = agree(test_g, test_v)\n",
    "mu, sigma = agree.get_z_dist()\n",
    "mu = mu.detach().cpu().numpy()\n",
    "sigma = sigma.detach().cpu().numpy()\n",
    "print(mu.shape, sigma.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cbook as cbook\n",
    "print(mu_embedded.shape, sigma_embedded.shape)\n",
    "print(cold_size)\n",
    "print(sigma.shape)\n",
    "sigma_embedded = np.linalg.norm(sigma, axis=1) #TSNE(n_components=1).fit_transform(sigma)\n",
    "s_max = max(sigma_embedded)\n",
    "s_min = min(sigma_embedded) \n",
    "sigma_embedded = (sigma_embedded - s_min) / (s_max-s_min)\n",
    "print(sigma_embedded.shape)\n",
    "mu_embedded = TSNE(n_components=1).fit_transform(mu)\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "#print(sigma_embedded)\n",
    "ax.scatter(mu[:cold_size, 0], sigma_embedded[:cold_size], s=10, label='new groups')\n",
    "ax.scatter(mu[cold_size:, 0], sigma_embedded[cold_size:], s=10, label='existing groups')\n",
    "\n",
    "\n",
    "#ax.scatter(mu_embedded[cold_size:, 0], mu_embedded[cold_size:, 1], s=sigma_embedded[cold_size:]*500, alpha=0.5)\n",
    "#ax.scatter(mu_embedded[:cold_size, 0], mu_embedded[:cold_size, 1], s=sigma_embedded[:cold_size]*500, alpha=0.5)\n",
    "#ax.legend(ncol=2, loc=(0.1, 1.1))\n",
    "ax.set_xlabel(r'$\\mu_z$', fontsize=15)\n",
    "ax.set_ylabel(r'$\\sigma_z$', fontsize=15)\n",
    "#ax.set_title('Volume and percent change')\n",
    "\n",
    "ax.grid(True)\n",
    "fig.tight_layout()\n",
    "plt.savefig('figures/tsne_cmfncf.pdf', bbox_inches=\"tight\") \n",
    "#plt.savefig('figures/tsne_legend.pdf', bbox_inches=\"tight\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utest_one_group(x, model, Ks, group_trainRatings, group_testRatings, num_items,thresholds, num_repeat, tor):\n",
    "    #rating = x[0]\n",
    "    g = x #group 1개 들어옴\n",
    "\n",
    "    try:\n",
    "        training_items = group_trainRatings[g]\n",
    "    except Exception:\n",
    "        training_items = []\n",
    "\n",
    "    group_pos_test = group_testRatings[g]\n",
    "\n",
    "    all_items = set(range(num_items))\n",
    "\n",
    "    test_items = list(all_items-set(training_items))\n",
    "    one_group_batch = np.full(len(test_items),g)\n",
    "    group_var = torch.LongTensor(one_group_batch)\n",
    "    item_var = torch.LongTensor(test_items)\n",
    "\n",
    "    rating_mean = 0\n",
    "    rating_variance = 0\n",
    "    for _ in range(num_repeat):\n",
    "        rating = model(group_var, item_var).detach().cpu()\n",
    "        rating_mean += rating\n",
    "        rating_variance += torch.square(rating)\n",
    "    rating_mean = rating_mean / num_repeat\n",
    "    rating_variance = rating_variance/num_repeat - torch.square(rating_mean)\n",
    "\n",
    "    \n",
    "    EPS = 1e-8\n",
    "    entropy = - rating_mean * torch.log(rating_mean+EPS)- (1.0-rating_mean)*torch.log(1.0-rating_mean+EPS)\n",
    "    #mu, sig = model.get_z_dist()\n",
    "    #print(torch.max(sig), torch.min(sig))\n",
    "    #print(torch.max(rating_variance), torch.min(rating_variance))\n",
    "    #sig = torch.norm(sig, dim=1, keepdim=True)/np.sqrt(32)/2\n",
    "    \n",
    "    \n",
    "    #max_var = torch.max(rating_variance)+EPS\n",
    "    #min_var = torch.min(rating_variance)+EPS\n",
    "    #entropy = (rating_variance-min_var)/(max_var-min_var)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #entropy = 4*rating_mean*(1.0-rating_mean)\n",
    "    #entropy = (rating_variance-rating_variance.min())/((rating_variance.max()-rating_variance.min()+1e-8))\n",
    "    \n",
    "    \n",
    "    #ipdb.set_trace()\n",
    "    \n",
    "    results = []\n",
    "    for threshold in thresholds:\n",
    "        indices = torch.where(entropy <=threshold)[0]\n",
    "\n",
    "        utest_items = [test_items[i] for i in indices.tolist()]\n",
    "        urating = torch.index_select(rating_mean, 0, indices)\n",
    "        \n",
    "        pos_urating = torch.where(urating >=tor)[0].tolist()\n",
    "        \n",
    "        urating = urating.cpu().numpy()\n",
    "        pt = len(set(pos_urating).intersection(group_pos_test))\n",
    "        nt = len(urating) - len(pos_urating) - (len(group_pos_test)-pt)\n",
    "        #print()\n",
    "        acc = 0\n",
    "        if len(urating) > 0:\n",
    "            acc = (pt+nt)/len(urating)\n",
    "\n",
    "        r, auc = ranklist_by_sorted(group_pos_test, utest_items, urating, Ks)\n",
    "        \n",
    "        ret = get_performance(group_pos_test, r, auc, Ks)\n",
    "        \n",
    "        ret['acc'] = acc\n",
    "        results.append(ret)\n",
    "    return results\n",
    "\n",
    "def utest(model, groups_to_test, Ks, group_trainRatings, num_items, batch_test_flag = False, thresholds=[1.0,], num_repeat=1, tor=0.9):\n",
    "    result = {}\n",
    "    for threshold in thresholds:\n",
    "        result[threshold] = {'precision': np.zeros(len(Ks)), 'recall': np.zeros(len(Ks)), 'ndcg': np.zeros(len(Ks)),\n",
    "                              'hit_ratio': np.zeros(len(Ks)), 'auc': 0., 'acc': 0.}\n",
    "\n",
    "\n",
    "    test_groups = groups_to_test\n",
    "    n_test_groups = len(test_groups)\n",
    "    #n_group_batchs = n_test_groups // g_batch_size + 1\n",
    "    #print(n_group_batchs)\n",
    "    #count = 0\n",
    "    for g_id in test_groups:\n",
    "        re = utest_one_group(g_id, model, Ks, group_trainRatings, test_groups, num_items,thresholds=thresholds, num_repeat=num_repeat, tor=tor)\n",
    "        #for re in batch_result:\n",
    "        for i, threshold in enumerate(thresholds):\n",
    "            result[threshold]['precision'] += re[i]['precision']/n_test_groups\n",
    "            result[threshold]['recall'] += re[i]['recall']/n_test_groups\n",
    "            result[threshold]['ndcg'] += re[i]['ndcg']/n_test_groups\n",
    "            result[threshold]['hit_ratio'] += re[i]['hit_ratio']/n_test_groups\n",
    "            result[threshold]['auc'] += re[i]['auc']/n_test_groups\n",
    "            print(result[threshold]['auc'],re[i]['auc'])\n",
    "            result[threshold]['acc'] += re[i]['acc']/n_test_groups\n",
    "        #print(re['hit_ratio'])\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "def uevaluation(model, groups_to_test, Ks, trainRatings, num_items, thresholds=[1.0,], num_repeat=1, tor = 0.9):\n",
    "    model.eval()\n",
    "    t2 = time()\n",
    "\n",
    "    ret = utest(model, groups_to_test, Ks, trainRatings, num_items,thresholds=thresholds, num_repeat=num_repeat, tor=tor) #See batch_test for test()\n",
    "\n",
    "    print('\\t Evaluation done [%.1f s]' % (time() - t2))\n",
    "    for threshold in thresholds:\n",
    "        print('Threshold:', threshold)\n",
    "        for i, k in enumerate(Ks):\n",
    "            print('\\t\\t @%d: HR = %.4f, NDCG = %.4f, Rec = %.4f, Precision = %.4f, ACC = %.4f' % (k, ret[threshold]['hit_ratio'][i], ret[threshold]['ndcg'][i], ret[threshold]['recall'][i], ret[threshold]['precision'][i], ret[threshold]['acc']))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agree = VARGR_NCF(num_users, num_items, num_groups, config.embedding_size, gu_dict, config.drop_ratio).cuda()\n",
    "agree.load_state_dict(torch.load('weights/VarGrNCF_meetup.ca_32_0.01_4_57'))\n",
    "ret_cold = None\n",
    "ret_warm = None\n",
    "for tor in [0.5,]:\n",
    "    print(tor)\n",
    "    tttt = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    #print('total')\n",
    "    #ret_total = uevaluation(agree, dataset.group_testRatings, config.topK[:2], dataset.group_trainRatings, dataset.num_items, thresholds=tttt, num_repeat=5, tor=tor)\n",
    "    print('cold')\n",
    "    ret_cold = uevaluation(agree, test_cold, [5, 10, 20, 50], dataset.group_trainRatings, dataset.num_items, thresholds=tttt, num_repeat=5, tor=tor)\n",
    "    print('warm')\n",
    "    ret_warm = uevaluation(agree, test_warm, [5, 10, 20, 50], dataset.group_trainRatings, dataset.num_items, thresholds=tttt, num_repeat=5, tor=tor)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_true=[1,1,1], y_score=[0.1, 0.2, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
