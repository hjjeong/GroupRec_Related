{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "#Python Libs\n",
    "import numpy as np\n",
    "from time import time\n",
    "import datetime\n",
    "import gc\n",
    "#Implementations\n",
    "from model.soagree import SoAGREE\n",
    "from config_soagree import Config\n",
    "from dataset_Meetup import GDataset\n",
    "from batch_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_loader, epoch_id, config):\n",
    "    # user trainning\n",
    "    learning_rates = config.lr\n",
    "    # learning rate decay\n",
    "    lr = learning_rates[0]\n",
    "    if epoch_id >= 20 and epoch_id < 50:\n",
    "        lr = learning_rates[1]\n",
    "    elif epoch_id >=50:\n",
    "        lr = learning_rates[2]\n",
    "    # lr decay\n",
    "    # if epoch_id % 5 == 0:\n",
    "    #     lr /= 2\n",
    "    t1 = time()\n",
    "    # optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), 0.005)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    *_, last = train_loader\n",
    "    model.train()\n",
    "    for batch_id, (g, pi_ni) in enumerate(train_loader):\n",
    "        # Data Load\n",
    "        group_input = g\n",
    "        pos_item_input = pi_ni[:, 0]\n",
    "        neg_item_input = pi_ni[:, 1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        \n",
    "        pos_prediction = model(group_input, pos_item_input)\n",
    "        neg_prediction = model(group_input, neg_item_input)\n",
    "\n",
    "        # Loss\n",
    "        loss = torch.mean((pos_prediction - neg_prediction -1) **2)\n",
    "        # record loss history\n",
    "        #print(\"batch_id: \" + str(batch_id) + \" loss: \" + str(loss.item()))\n",
    "        if not torch.isinf(loss.data) and not torch.isnan(loss.data):\n",
    "            losses.append(float(loss.item()))\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        del group_input, pos_item_input, neg_item_input\n",
    "\n",
    "    print('Iteration %d,\\tloss: [%.4f], time: [%.1fs]' % (epoch_id, np.mean(np.array(losses)), time() - t1))\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, groups_to_test, Ks, trainRatings, num_items):\n",
    "    model.eval()\n",
    "    t2 = time()\n",
    "    ret = test(model, groups_to_test, Ks, trainRatings, num_items) #See batch_test\n",
    "\n",
    "    print('\\t Evaluation done [%.1f s]' % (time() - t2))\n",
    "    for i, k in enumerate(Ks):\n",
    "        print('\\t\\t @%d: HR = %.4f, NDCG = %.4f, Rec = %.4f' % (k, ret['hit_ratio'][i], ret['ndcg'][i], ret['recall'][i]))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "douban 128 256\n"
     ]
    }
   ],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_groups: 92489 num_users: 63893 num_items: 15741\n"
     ]
    }
   ],
   "source": [
    "dataset = GDataset(config.user_dataset, config.group_dataset, config.user_in_group_path, 1)\n",
    "num_groups, num_users, num_items = dataset.num_groups, dataset.num_users, dataset.num_items\n",
    "print(\"num_groups: \"+str(num_groups)+\" num_users: \"+str(num_users)+\" num_items: \"+str(num_items))\n",
    "gu_dict = dataset.gu_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_warm = dataset.load_rating_file_as_dict(config.group_dataset + \".test.rating_warm\")\n",
    "test_cold = dataset.load_rating_file_as_dict(config.group_dataset + \".test.rating_cold\")\n",
    "#ret = evaluation(agree, test_warm, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "#ret = evaluation(agree, test_cold, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "valid = dataset.load_rating_file_as_dict(config.group_dataset + \".valid.rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def gen_user_follow_dict(path):\n",
    "    g_m_d = {}\n",
    "    with open(path, 'r') as f:\n",
    "        line = f.readline().strip()\n",
    "        while line != None and line != \"\":\n",
    "            a = line.split(':')\n",
    "            g = int(a[0])\n",
    "            g_m_d[g] = []\n",
    "            for m in a[1].split(' '):\n",
    "                if m is None or m == '':\n",
    "                    continue\n",
    "                g_m_d[g].append(int(m))\n",
    "            line = f.readline().strip()\n",
    "    return g_m_d\n",
    "u_f_d = gen_user_follow_dict(config.path+\"userFollow.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGREE: embedding size 32, run Iteration: 128, #neg: 4\n",
      "Iteration 0,\tloss: [0.7279], time: [1703.8s]\n",
      "\t Evaluation done [6356.4 s]\n",
      "\t\t @5: HR = 0.0000, NDCG = 0.0000, Rec = 0.0000\n",
      "\t\t @10: HR = 0.0000, NDCG = 0.0000, Rec = 0.0000\n",
      "Iteration 1,\tloss: [0.3197], time: [1706.3s]\n",
      "Iteration 2,\tloss: [0.1516], time: [1705.6s]\n",
      "Iteration 3,\tloss: [0.0945], time: [1707.5s]\n",
      "\t Evaluation done [6388.5 s]\n",
      "\t\t @5: HR = 0.0042, NDCG = 0.0032, Rec = 0.0042\n",
      "\t\t @10: HR = 0.0127, NDCG = 0.0058, Rec = 0.0127\n",
      "Iteration 4,\tloss: [0.0692], time: [1702.1s]\n",
      "Iteration 5,\tloss: [0.0572], time: [1703.5s]\n",
      "Iteration 6,\tloss: [0.0497], time: [1702.3s]\n",
      "\t Evaluation done [6340.3 s]\n",
      "\t\t @5: HR = 0.0106, NDCG = 0.0069, Rec = 0.0106\n",
      "\t\t @10: HR = 0.0191, NDCG = 0.0096, Rec = 0.0191\n",
      "Iteration 7,\tloss: [0.0455], time: [1705.9s]\n",
      "Iteration 8,\tloss: [0.0427], time: [1705.6s]\n",
      "Iteration 9,\tloss: [0.0401], time: [1703.0s]\n",
      "\t Evaluation done [6366.8 s]\n",
      "\t\t @5: HR = 0.0042, NDCG = 0.0019, Rec = 0.0042\n",
      "\t\t @10: HR = 0.0191, NDCG = 0.0067, Rec = 0.0191\n",
      "Iteration 10,\tloss: [0.0385], time: [1708.8s]\n",
      "Iteration 11,\tloss: [0.0375], time: [1705.4s]\n",
      "Iteration 12,\tloss: [0.0365], time: [1703.5s]\n",
      "\t Evaluation done [6339.6 s]\n",
      "\t\t @5: HR = 0.0148, NDCG = 0.0070, Rec = 0.0148\n",
      "\t\t @10: HR = 0.0275, NDCG = 0.0111, Rec = 0.0275\n",
      "Iteration 13,\tloss: [0.0357], time: [1708.1s]\n",
      "Iteration 14,\tloss: [0.0349], time: [1707.2s]\n",
      "Iteration 15,\tloss: [0.0340], time: [1708.4s]\n",
      "\t Evaluation done [6351.6 s]\n",
      "\t\t @5: HR = 0.0127, NDCG = 0.0076, Rec = 0.0127\n",
      "\t\t @10: HR = 0.0254, NDCG = 0.0117, Rec = 0.0254\n",
      "Iteration 16,\tloss: [0.0331], time: [1704.2s]\n",
      "Iteration 17,\tloss: [0.0325], time: [1708.1s]\n",
      "Iteration 18,\tloss: [0.0320], time: [1704.8s]\n",
      "\t Evaluation done [6362.9 s]\n",
      "\t\t @5: HR = 0.0148, NDCG = 0.0094, Rec = 0.0148\n",
      "\t\t @10: HR = 0.0339, NDCG = 0.0156, Rec = 0.0339\n",
      "Iteration 19,\tloss: [0.0316], time: [1671.3s]\n",
      "Iteration 20,\tloss: [0.0312], time: [1461.5s]\n",
      "Iteration 21,\tloss: [0.0306], time: [1462.0s]\n",
      "\t Evaluation done [4871.8 s]\n",
      "\t\t @5: HR = 0.0106, NDCG = 0.0056, Rec = 0.0106\n",
      "\t\t @10: HR = 0.0233, NDCG = 0.0099, Rec = 0.0233\n",
      "Iteration 22,\tloss: [0.0301], time: [1462.5s]\n",
      "Iteration 23,\tloss: [0.0296], time: [1461.6s]\n",
      "Iteration 24,\tloss: [0.0294], time: [1462.2s]\n",
      "\t Evaluation done [4884.0 s]\n",
      "\t\t @5: HR = 0.0191, NDCG = 0.0097, Rec = 0.0191\n",
      "\t\t @10: HR = 0.0318, NDCG = 0.0138, Rec = 0.0318\n",
      "Iteration 25,\tloss: [0.0291], time: [1461.2s]\n",
      "Iteration 26,\tloss: [0.0288], time: [1461.8s]\n",
      "Iteration 27,\tloss: [0.0287], time: [1462.6s]\n"
     ]
    }
   ],
   "source": [
    "agree = SoAGREE(num_users, num_items, num_groups, num_users, config.embedding_size, gu_dict, None, config.drop_ratio).cuda()\n",
    "best_checkpoint = -1.0\n",
    "best_weights_path = None\n",
    "for num_negatives in config.num_negatives:\n",
    "    dataset.num_negatives = num_negatives\n",
    "    print(\"AGREE: embedding size %d, run Iteration: %d, #neg: %d\" %(config.embedding_size, config.epoch, num_negatives))\n",
    "    # train the model\n",
    "    now = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    for epoch in range(config.epoch): \n",
    "        training(agree, dataset.get_group_dataloader(config.batch_size), epoch, config)\n",
    "\n",
    "\n",
    "        # Evaluation\n",
    "        if epoch % 3 == 0:\n",
    "            agree.eval()\n",
    "            with torch.no_grad():\n",
    "                #ret = evaluation(agree, dataset.group_testRatings, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "                ret = evaluation(agree, valid, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "                cur_checkpoint = ret['hit_ratio'][1]\n",
    "                #ret = evaluation(agree, test_cold, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "                #cur_checkpoint += ret['hit_ratio'][1]\n",
    "                #cur_checkpoint = cur_checkpoint/2\n",
    "                current_weights_path = 'weights/soagree_'+str(config.dataset)+\"_\"+str(config.embedding_size)+\"_\"+str(config.lr[0])+'_'+str(num_negatives)+'_'+str(epoch)\n",
    "                torch.save(agree.state_dict(), current_weights_path)\n",
    "                if best_checkpoint <= cur_checkpoint:\n",
    "                    best_weights_path = current_weights_path\n",
    "                    best_checkpoint = cur_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agree = SoAGREE(num_users, num_items, num_groups, num_users, config.embedding_size, gu_dict, None, config.drop_ratio).cuda()\n",
    "agree.load_state_dict(torch.load(best_weights_path))\n",
    "print(best_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cold')\n",
    "ret = evaluation(agree, test_cold, config.topK[:2], dataset.group_trainRatings, dataset.num_items)\n",
    "print('warm')\n",
    "ret = evaluation(agree, test_warm, config.topK[:2], dataset.group_trainRatings, dataset.num_items)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
